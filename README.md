
# ğŸ“Š Planejamento de ProduÃ§Ã£o com Aprendizado por ReforÃ§o

Bem-vindo ao projeto **Planejamento de ProduÃ§Ã£o com Aprendizado por ReforÃ§o**! Este repositÃ³rio contÃ©m um notebook em Python que implementa o aprendizado por reforÃ§o para resolver o problema de sequenciamento de produÃ§Ã£o em uma fÃ¡brica. O objetivo Ã© otimizar a produÃ§Ã£o para atender Ã s demandas, minimizando custos relacionados ao estoque e ao nÃ£o atendimento. ğŸš€

## ğŸ“š Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [DescriÃ§Ã£o do Problema](#descriÃ§Ã£o-do-problema)
- [Estrutura dos Dados de Entrada](#estrutura-dos-dados-de-entrada)
- [Como Funciona o Aprendizado por ReforÃ§o](#como-funciona-o-aprendizado-por-reforÃ§o)
- [DependÃªncias](#dependÃªncias)
- [Uso](#uso)
- [SaÃ­da](#saÃ­da)

## ğŸ“‹ VisÃ£o Geral

Este notebook utiliza o aprendizado por reforÃ§o para otimizar o sequenciamento de produÃ§Ã£o em quatro linhas de produÃ§Ã£o, com o objetivo de atender Ã  demanda de 20 produtos, minimizando os custos de estoque e a penalidade por nÃ£o atendimento.

## ğŸ§  Como Funciona o Aprendizado por ReforÃ§o

O aprendizado por reforÃ§o (RL) Ã© uma tÃ©cnica onde um agente aprende a tomar decisÃµes em um ambiente para maximizar uma recompensa cumulativa. A seguir estÃ£o os principais conceitos aplicados:

1. **Estado:** Representa a situaÃ§Ã£o atual do estoque e da produÃ§Ã£o de cada produto.
2. **AÃ§Ã£o:** DecisÃ£o sobre qual linha de produÃ§Ã£o utilizar para cada produto.
3. **Recompensa:** Calculada com base em como a aÃ§Ã£o atende Ã  demanda e minimiza o excesso de estoque.

O agente aprende uma polÃ­tica Ã³tima atravÃ©s da interaÃ§Ã£o repetida com o ambiente, ajustando suas aÃ§Ãµes para maximizar a recompensa acumulada.

## ğŸ—‚ Estrutura dos Dados de Entrada

1. **Demandas:** Dados sobre as demandas mensais de cada produto.
2. **Estoque Inicial:** Estoque inicial disponÃ­vel para cada produto.
3. **Produtividade:** Produtividade de cada linha de produÃ§Ã£o.
4. **Capacidades:** Capacidades mÃ¡ximas das linhas de produÃ§Ã£o.

Os dados sÃ£o carregados de um arquivo Excel com planilhas separadas para cada conjunto de informaÃ§Ãµes.

## ğŸ›  DependÃªncias

Certifique-se de ter as seguintes dependÃªncias instaladas:

- Python 3.x
- Pandas
- NumPy

Instale-as usando pip:

```bash
pip install requirements.txt
```

## ğŸš€ Uso

1. Clone este repositÃ³rio e execute o notebook:

   ```bash
   git clone <https://github.com/vtatekawa/production-optimization-reinforcement-learning>
   cd <production-optimization-reinforcement-learning>
   jupyter notebook productionPlanningRL.ipynb
   ```

2. Carregue seus dados de produÃ§Ã£o nos formatos adequados (exemplos estÃ£o na pasta `input`).
3. Execute todas as cÃ©lulas do notebook para otimizar o plano de produÃ§Ã£o.

## ğŸ“ˆ SaÃ­da

ApÃ³s executar o notebook, vocÃª obterÃ¡:

- **Plano de ProduÃ§Ã£o Otimizado:** SequÃªncia de produÃ§Ã£o para atender Ã s demandas em um arquivo excel na pasta output.

---

Feito com ğŸ§  por [Vitor Tatekawa](https://github.com/vtatekawa)
